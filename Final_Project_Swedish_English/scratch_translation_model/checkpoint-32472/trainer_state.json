{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 32472,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.046193643754619367,
      "grad_norm": 1.340250849723816,
      "learning_rate": 0.00029538987435328895,
      "loss": 7.4171,
      "step": 500
    },
    {
      "epoch": 0.09238728750923873,
      "grad_norm": 0.24677477777004242,
      "learning_rate": 0.00029077050997782704,
      "loss": 1.4118,
      "step": 1000
    },
    {
      "epoch": 0.1385809312638581,
      "grad_norm": 0.3009412884712219,
      "learning_rate": 0.00028615114560236513,
      "loss": 0.5403,
      "step": 1500
    },
    {
      "epoch": 0.18477457501847747,
      "grad_norm": 0.33280807733535767,
      "learning_rate": 0.00028153178122690317,
      "loss": 0.4986,
      "step": 2000
    },
    {
      "epoch": 0.2309682187730968,
      "grad_norm": 0.37633955478668213,
      "learning_rate": 0.00027691241685144126,
      "loss": 0.4699,
      "step": 2500
    },
    {
      "epoch": 0.2771618625277162,
      "grad_norm": 0.24345985054969788,
      "learning_rate": 0.0002722930524759793,
      "loss": 0.4579,
      "step": 3000
    },
    {
      "epoch": 0.32335550628233556,
      "grad_norm": 0.5991335511207581,
      "learning_rate": 0.0002676736881005174,
      "loss": 0.4507,
      "step": 3500
    },
    {
      "epoch": 0.36954915003695493,
      "grad_norm": 0.2965870797634125,
      "learning_rate": 0.0002630543237250554,
      "loss": 0.4489,
      "step": 4000
    },
    {
      "epoch": 0.4157427937915743,
      "grad_norm": 0.7338363528251648,
      "learning_rate": 0.00025843495934959346,
      "loss": 0.444,
      "step": 4500
    },
    {
      "epoch": 0.4619364375461936,
      "grad_norm": 0.2655874192714691,
      "learning_rate": 0.00025381559497413155,
      "loss": 0.4334,
      "step": 5000
    },
    {
      "epoch": 0.508130081300813,
      "grad_norm": 0.23117583990097046,
      "learning_rate": 0.0002491962305986696,
      "loss": 0.4404,
      "step": 5500
    },
    {
      "epoch": 0.5543237250554324,
      "grad_norm": 0.8497489094734192,
      "learning_rate": 0.0002445768662232077,
      "loss": 0.4437,
      "step": 6000
    },
    {
      "epoch": 0.6005173688100517,
      "grad_norm": 1.5582990646362305,
      "learning_rate": 0.00023995750184774574,
      "loss": 0.4286,
      "step": 6500
    },
    {
      "epoch": 0.6467110125646711,
      "grad_norm": 0.9028446674346924,
      "learning_rate": 0.00023533813747228378,
      "loss": 0.4364,
      "step": 7000
    },
    {
      "epoch": 0.6929046563192904,
      "grad_norm": 2.188967704772949,
      "learning_rate": 0.00023071877309682187,
      "loss": 0.4279,
      "step": 7500
    },
    {
      "epoch": 0.7390983000739099,
      "grad_norm": 0.284199595451355,
      "learning_rate": 0.0002260994087213599,
      "loss": 0.4233,
      "step": 8000
    },
    {
      "epoch": 0.7852919438285292,
      "grad_norm": 0.14120732247829437,
      "learning_rate": 0.000221480044345898,
      "loss": 0.4286,
      "step": 8500
    },
    {
      "epoch": 0.8314855875831486,
      "grad_norm": 0.7947260141372681,
      "learning_rate": 0.00021686067997043603,
      "loss": 0.422,
      "step": 9000
    },
    {
      "epoch": 0.8776792313377679,
      "grad_norm": 0.79494708776474,
      "learning_rate": 0.00021224131559497412,
      "loss": 0.4247,
      "step": 9500
    },
    {
      "epoch": 0.9238728750923872,
      "grad_norm": 0.43085581064224243,
      "learning_rate": 0.00020762195121951216,
      "loss": 0.431,
      "step": 10000
    },
    {
      "epoch": 0.9700665188470067,
      "grad_norm": 0.9295053482055664,
      "learning_rate": 0.00020300258684405025,
      "loss": 0.4215,
      "step": 10500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.42384952306747437,
      "eval_runtime": 179.1598,
      "eval_samples_per_second": 53.701,
      "eval_steps_per_second": 6.715,
      "step": 10824
    },
    {
      "epoch": 1.016260162601626,
      "grad_norm": 1.5033979415893555,
      "learning_rate": 0.0001983832224685883,
      "loss": 0.411,
      "step": 11000
    },
    {
      "epoch": 1.0624538063562454,
      "grad_norm": 4.663934707641602,
      "learning_rate": 0.00019376385809312638,
      "loss": 0.4181,
      "step": 11500
    },
    {
      "epoch": 1.1086474501108647,
      "grad_norm": 0.9512706398963928,
      "learning_rate": 0.00018914449371766444,
      "loss": 0.4214,
      "step": 12000
    },
    {
      "epoch": 1.154841093865484,
      "grad_norm": 1.3735862970352173,
      "learning_rate": 0.0001845251293422025,
      "loss": 0.4211,
      "step": 12500
    },
    {
      "epoch": 1.2010347376201036,
      "grad_norm": 0.21010364592075348,
      "learning_rate": 0.00017990576496674057,
      "loss": 0.4154,
      "step": 13000
    },
    {
      "epoch": 1.247228381374723,
      "grad_norm": 1.7492311000823975,
      "learning_rate": 0.00017528640059127863,
      "loss": 0.4183,
      "step": 13500
    },
    {
      "epoch": 1.2934220251293422,
      "grad_norm": 1.5571223497390747,
      "learning_rate": 0.0001706670362158167,
      "loss": 0.4135,
      "step": 14000
    },
    {
      "epoch": 1.3396156688839616,
      "grad_norm": 0.9618437886238098,
      "learning_rate": 0.00016604767184035476,
      "loss": 0.412,
      "step": 14500
    },
    {
      "epoch": 1.3858093126385809,
      "grad_norm": 0.8493407368659973,
      "learning_rate": 0.00016142830746489282,
      "loss": 0.4136,
      "step": 15000
    },
    {
      "epoch": 1.4320029563932004,
      "grad_norm": 1.7422553300857544,
      "learning_rate": 0.00015680894308943088,
      "loss": 0.4186,
      "step": 15500
    },
    {
      "epoch": 1.4781966001478197,
      "grad_norm": 1.6968214511871338,
      "learning_rate": 0.00015218957871396895,
      "loss": 0.4184,
      "step": 16000
    },
    {
      "epoch": 1.524390243902439,
      "grad_norm": 0.46007871627807617,
      "learning_rate": 0.000147570214338507,
      "loss": 0.4189,
      "step": 16500
    },
    {
      "epoch": 1.5705838876570584,
      "grad_norm": 0.4609219431877136,
      "learning_rate": 0.00014295084996304507,
      "loss": 0.4162,
      "step": 17000
    },
    {
      "epoch": 1.6167775314116777,
      "grad_norm": 0.5415406227111816,
      "learning_rate": 0.00013833148558758314,
      "loss": 0.4168,
      "step": 17500
    },
    {
      "epoch": 1.6629711751662972,
      "grad_norm": 1.0856784582138062,
      "learning_rate": 0.0001337121212121212,
      "loss": 0.413,
      "step": 18000
    },
    {
      "epoch": 1.7091648189209163,
      "grad_norm": 1.0346462726593018,
      "learning_rate": 0.00012909275683665927,
      "loss": 0.409,
      "step": 18500
    },
    {
      "epoch": 1.7553584626755359,
      "grad_norm": 0.8678789138793945,
      "learning_rate": 0.00012447339246119733,
      "loss": 0.4109,
      "step": 19000
    },
    {
      "epoch": 1.8015521064301552,
      "grad_norm": 0.7461784482002258,
      "learning_rate": 0.00011985402808573539,
      "loss": 0.4104,
      "step": 19500
    },
    {
      "epoch": 1.8477457501847745,
      "grad_norm": 5.539572715759277,
      "learning_rate": 0.00011523466371027346,
      "loss": 0.411,
      "step": 20000
    },
    {
      "epoch": 1.893939393939394,
      "grad_norm": 0.3176165521144867,
      "learning_rate": 0.00011061529933481152,
      "loss": 0.4149,
      "step": 20500
    },
    {
      "epoch": 1.9401330376940134,
      "grad_norm": 0.5398746728897095,
      "learning_rate": 0.00010599593495934958,
      "loss": 0.416,
      "step": 21000
    },
    {
      "epoch": 1.9863266814486327,
      "grad_norm": 9.302287101745605,
      "learning_rate": 0.00010137657058388765,
      "loss": 0.411,
      "step": 21500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.41252732276916504,
      "eval_runtime": 178.7387,
      "eval_samples_per_second": 53.827,
      "eval_steps_per_second": 6.73,
      "step": 21648
    },
    {
      "epoch": 2.032520325203252,
      "grad_norm": 0.43423986434936523,
      "learning_rate": 9.675720620842571e-05,
      "loss": 0.4085,
      "step": 22000
    },
    {
      "epoch": 2.0787139689578713,
      "grad_norm": 0.6785681247711182,
      "learning_rate": 9.213784183296377e-05,
      "loss": 0.4117,
      "step": 22500
    },
    {
      "epoch": 2.124907612712491,
      "grad_norm": 0.2615870237350464,
      "learning_rate": 8.751847745750184e-05,
      "loss": 0.4032,
      "step": 23000
    },
    {
      "epoch": 2.17110125646711,
      "grad_norm": 0.8246556520462036,
      "learning_rate": 8.28991130820399e-05,
      "loss": 0.4058,
      "step": 23500
    },
    {
      "epoch": 2.2172949002217295,
      "grad_norm": 0.9357815384864807,
      "learning_rate": 7.827974870657796e-05,
      "loss": 0.409,
      "step": 24000
    },
    {
      "epoch": 2.263488543976349,
      "grad_norm": 3.798757791519165,
      "learning_rate": 7.366038433111603e-05,
      "loss": 0.4048,
      "step": 24500
    },
    {
      "epoch": 2.309682187730968,
      "grad_norm": 0.7913480401039124,
      "learning_rate": 6.904101995565409e-05,
      "loss": 0.4055,
      "step": 25000
    },
    {
      "epoch": 2.3558758314855877,
      "grad_norm": 0.54826819896698,
      "learning_rate": 6.442165558019215e-05,
      "loss": 0.404,
      "step": 25500
    },
    {
      "epoch": 2.402069475240207,
      "grad_norm": 0.31081968545913696,
      "learning_rate": 5.980229120473022e-05,
      "loss": 0.4079,
      "step": 26000
    },
    {
      "epoch": 2.4482631189948263,
      "grad_norm": 3.173313856124878,
      "learning_rate": 5.518292682926828e-05,
      "loss": 0.4019,
      "step": 26500
    },
    {
      "epoch": 2.494456762749446,
      "grad_norm": 0.5258191823959351,
      "learning_rate": 5.056356245380635e-05,
      "loss": 0.4137,
      "step": 27000
    },
    {
      "epoch": 2.540650406504065,
      "grad_norm": 0.4528752565383911,
      "learning_rate": 4.5944198078344416e-05,
      "loss": 0.4119,
      "step": 27500
    },
    {
      "epoch": 2.5868440502586845,
      "grad_norm": 1.3856687545776367,
      "learning_rate": 4.132483370288248e-05,
      "loss": 0.4024,
      "step": 28000
    },
    {
      "epoch": 2.6330376940133036,
      "grad_norm": 0.732854962348938,
      "learning_rate": 3.670546932742054e-05,
      "loss": 0.4081,
      "step": 28500
    },
    {
      "epoch": 2.679231337767923,
      "grad_norm": 0.6136332750320435,
      "learning_rate": 3.208610495195861e-05,
      "loss": 0.4078,
      "step": 29000
    },
    {
      "epoch": 2.7254249815225426,
      "grad_norm": 3.883399724960327,
      "learning_rate": 2.746674057649667e-05,
      "loss": 0.3985,
      "step": 29500
    },
    {
      "epoch": 2.7716186252771617,
      "grad_norm": 0.9169173836708069,
      "learning_rate": 2.2847376201034734e-05,
      "loss": 0.3944,
      "step": 30000
    },
    {
      "epoch": 2.8178122690317813,
      "grad_norm": 0.8857237100601196,
      "learning_rate": 1.8228011825572797e-05,
      "loss": 0.4031,
      "step": 30500
    },
    {
      "epoch": 2.864005912786401,
      "grad_norm": 0.1021345853805542,
      "learning_rate": 1.3608647450110864e-05,
      "loss": 0.4038,
      "step": 31000
    },
    {
      "epoch": 2.91019955654102,
      "grad_norm": 0.3249965012073517,
      "learning_rate": 8.989283074648928e-06,
      "loss": 0.4015,
      "step": 31500
    },
    {
      "epoch": 2.9563932002956395,
      "grad_norm": 0.4595280885696411,
      "learning_rate": 4.3699186991869915e-06,
      "loss": 0.3966,
      "step": 32000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.407182902097702,
      "eval_runtime": 181.979,
      "eval_samples_per_second": 52.869,
      "eval_steps_per_second": 6.611,
      "step": 32472
    }
  ],
  "logging_steps": 500,
  "max_steps": 32472,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8789231929393152.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
