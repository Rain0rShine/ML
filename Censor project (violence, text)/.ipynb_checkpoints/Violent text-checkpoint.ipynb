{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e23a158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b763685",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.read_csv(\"diffusion_db_unaltered.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38226890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>image_nsfw</th>\n",
       "      <th>prompt_nsfw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a portrait of a female robot made from code, v...</td>\n",
       "      <td>0.554853</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a portrait of a female robot made from a cloud...</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>only memories remain, trending on artstation</td>\n",
       "      <td>0.062496</td>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dream swimming pool with nobody</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.003586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a dog doing weights. epic oil painting.</td>\n",
       "      <td>0.181035</td>\n",
       "      <td>0.030822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  image_nsfw  prompt_nsfw\n",
       "0  a portrait of a female robot made from code, v...    0.554853     0.001621\n",
       "1  a portrait of a female robot made from a cloud...    0.153645     0.000707\n",
       "2      only memories remain, trending on artstation     0.062496     0.000425\n",
       "3                   dream swimming pool with nobody     0.030799     0.003586\n",
       "4           a dog doing weights. epic oil painting.     0.181035     0.030822"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2a552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   prompt       object \n",
      " 1   image_nsfw   float64\n",
      " 2   prompt_nsfw  float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "prompts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe760d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485ae05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486942e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f059a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "violenceWords = [\n",
    "    \"Violent\", \"Murder\", \"Bloodshed\" , \"Torture\", \"Gore\" , \"Abuse\" , \"Aggression\", \"Aggressive\", \"Assault\", \"Homicide\", \"Brutality\",\n",
    "    \"Slaughter\", \"Mutilation\", \"Carnage\", \"Bloodbath\", \"Execution\", \"Rape\", \"Terror\", \"Wounding\", \"Savagery\", \"Beating\", \"Killing\",\n",
    "    \"Massacre\", \"Violence\", \"Disfigurement\", \"War crimes\", \"Inhumane\", \"Strangulation\", \"Flogging\", \"Vicious\", \"Cut\", \"Burn\",\n",
    "    \"Self-harm\", \"Self harm\", \"Terrorism\", \"Gang\", \"Kidnapping\",\"Bombing\",\"Extermination\",\"Bloodcurdling\",\"Mauling\", \"Maul\",\n",
    "    \"trafficking\", \"violence\", \"Genocide\", \"Warfare\", \"Shooting\", \"maim\", \"Disembowelment\", \"Lynching\", \"Battering\",\n",
    "    \"Molest\", \"Molesting\", \"hostage\", \"suicide\", \"mob\", \"riot\", \"brutal\", \"threaten\", \"serial killer\", \"hitting\", \"kill\", \"wound\", \n",
    "    \"gun\"\n",
    "\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87f4660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d69e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit = pd.read_csv(\"en_explicit.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ab82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts['allowed'] = (prompts['prompt_nsfw'] < 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83666fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>image_nsfw</th>\n",
       "      <th>prompt_nsfw</th>\n",
       "      <th>allowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a portrait of a female robot made from code, v...</td>\n",
       "      <td>0.554853</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a portrait of a female robot made from a cloud...</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>only memories remain, trending on artstation</td>\n",
       "      <td>0.062496</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dream swimming pool with nobody</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a dog doing weights. epic oil painting.</td>\n",
       "      <td>0.181035</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  image_nsfw  prompt_nsfw  \\\n",
       "0  a portrait of a female robot made from code, v...    0.554853     0.001621   \n",
       "1  a portrait of a female robot made from a cloud...    0.153645     0.000707   \n",
       "2      only memories remain, trending on artstation     0.062496     0.000425   \n",
       "3                   dream swimming pool with nobody     0.030799     0.003586   \n",
       "4           a dog doing weights. epic oil painting.     0.181035     0.030822   \n",
       "\n",
       "   allowed  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef91631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc04f69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5100\\2762796738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mClassprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prompt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mNumprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prompt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\b\\w+\\b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prompt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prompts' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, row in prompts.head(5).iterrows():\n",
    "    Classprompt = row['prompt']\n",
    "    Numprompt = row['prompt']\n",
    "    \n",
    "    for word in re.findall(r'\\b\\w+\\b', row['prompt']):\n",
    "        if word not in df['Word'].values:\n",
    "            classification_value = classify_word(word)\n",
    "            numeric_value, interpreted_word = numberify(word)\n",
    "        else:\n",
    "            classification_value = df.loc[df['Word'] == word, 'Classification'].values[0]\n",
    "            numeric_value = df.loc[df['Word'] == word, 'Number'].values[0]\n",
    "        \n",
    "        Classprompt = Classprompt.replace(word, str(classification_value))\n",
    "        Numprompt = Numprompt.replace(word, str(numeric_value))\n",
    "    \n",
    "    prompts.at[idx, 'Classprompt'] = int(Classprompt) if Classprompt.isdigit() else Classprompt\n",
    "    prompts.at[idx, 'Numprompt'] = int(Numprompt) if Numprompt.isdigit() else Numprompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffc964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = prompts.head(100)\n",
    "if 'Guess allowed' in df_subset.columns and 'allowed' in df_subset.columns:\n",
    "    true_positives = (df_subset['Guess allowed'] == 1) & (df_subset['allowed'] == 1)\n",
    "    true_negatives = (df_subset['Guess allowed'] == 0) & (df_subset['allowed'] == 0)\n",
    "    false_positives = (df_subset['Guess allowed'] == 1) & (df_subset['allowed'] == 0)\n",
    "    false_negatives = (df_subset['Guess allowed'] == 0) & (df_subset['allowed'] == 1)\n",
    "    tp_count = true_positives.sum()\n",
    "    tn_count = true_negatives.sum()\n",
    "    fp_count = false_positives.sum()\n",
    "    fn_count = false_negatives.sum()\n",
    "    print(f\"True Positives (TP): {tp_count}\")\n",
    "    print(f\"True Negatives (TN): {tn_count}\")\n",
    "    print(f\"False Positives (FP): {fp_count}\")\n",
    "    print(f\"False Negatives (FN): {fn_count}\")\n",
    "    accuracy = (tp_count + tn_count) / len(df_subset)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"The required columns are not present in the first 100 rows.\")\n",
    "This code takes the first 100 rows then finds the true positives/negatives and false positives/negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5537d87b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1464\\2847469336.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprompts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allowed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prompt_nsfw'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prompts' is not defined"
     ]
    }
   ],
   "source": [
    "prompts['allowed'] = (prompts['prompt_nsfw'] < 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fb0d3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "iterable argument unpacking follows keyword argument unpacking (538242188.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\enichol\\AppData\\Local\\Temp\\ipykernel_1464\\538242188.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    sklearn.metrics.recall_score('allowed', 'Guess allowed', *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m iterable argument unpacking follows keyword argument unpacking\n"
     ]
    }
   ],
   "source": [
    "sklearn.metrics.recall_score('allowed', 'Guess allowed', *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4089817",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label. It should be one of ['Guess allowed', 'allowed']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1464\\1335481446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allowed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Guess allowed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m     \"\"\"\n\u001b[1;32m-> 1901\u001b[1;33m     _, r, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1902\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1354\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m   1357\u001b[0m                         \u001b[1;34mf\"pos_label={pos_label} is not a valid label. It \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m                         \u001b[1;34mf\"should be one of {present_labels}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label. It should be one of ['Guess allowed', 'allowed']"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall = recall_score(['allowed'], ['Guess allowed'], labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
    "print(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41f17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593c42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
