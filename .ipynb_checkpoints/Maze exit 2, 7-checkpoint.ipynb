{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13f97e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in c:\\users\\enichol\\appdata\\roaming\\python\\python39\\site-packages (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\enichol\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (1.21.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2c99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62962d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make maze\n",
    "# render_mode='human' \n",
    "maze=[\"FFFG\", \"SFFH\", \"FFFF\"]\n",
    "env = gym.make('FrozenLake-v1', desc=maze)\n",
    "# env = gym.make('FrozenLake-v1', desc=maze, render_mode='human')\n",
    "initial_state = env.reset()\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8949e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate - 0.5, discount - 0.5\n",
    "# Bellman Equation: (1-alpha)q(s, a) + alpha(R + gamma(max(q(s`, a`))))\n",
    "# Q Table Diagram\n",
    "#    Up  Down  Left  Right\n",
    "# 0\n",
    "# 1\n",
    "# 2\n",
    "# 3\n",
    "# 4\n",
    "# 5\n",
    "\n",
    "q = {\n",
    "    3: [0,0,0,0,0,0], # UP\n",
    "    1: [0,0,0,0,0,0], # DOWN\n",
    "    0: [0,0,0,0,0,0], # LEFT\n",
    "    2: [0,0,0,0,0,0] # RIGHT\n",
    "}\n",
    "cells =[\"S\", \"F\", \"F\", \"H\",\"F\",\"G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28491470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateQ(q, alpha, gamma, step, cell, reward):\n",
    "    row = [q[3][cell], q[1][cell], q[0][cell], q[2][cell]]\n",
    "    bell = (1-alpha)*(q[step][cell]) + alpha*(reward + (gamma*max(row)))\n",
    "    q[step][cell] = bell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38d83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#terminated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c909b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35504\\2425187538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"F\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"S\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"H\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Train Q-Model\n",
    "# Learning Rate - 0.5, Discount Rate - 0.5\n",
    "# Reward: +100 gift, -1 empty space, -100 lake\n",
    "# Belman Equation: (1-alpha)q(s,a) + alpha(R + gamma(max(s`, a`)))\n",
    "\n",
    "# Take a step (0: LEFT, 1: DOWN, 2: RIGHT, 3: UP)\n",
    "for episode in range(1000):\n",
    "    terminated = False\n",
    "    while not terminated:\n",
    "        # Take a step (0: LEFT, 1: DOWN, 2: RIGHT, 3: UP)\n",
    "        action = random.randint(0, 3)\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "        idx = new_state % len(q[3])\n",
    "        if cells[new_state] == \"F\" or cells[new_state] == \"S\":\n",
    "            reward = -1\n",
    "        elif cells[new_state] == \"H\":\n",
    "            reward = -100\n",
    "        else:\n",
    "            reward = 100\n",
    "        updateQ(q, 0.5, 0.5, action, idx, reward)\n",
    "    inital = env.reset()\n",
    "    terminated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9982ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(q)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
